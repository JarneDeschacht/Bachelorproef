%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Methodologie}{Methodology}}
\label{ch:methodologie}

In dit hoofdstuk zal er een experiment worden toegelicht die op een objectieve manier het begrijpend vermogen van de platformen zal beoordelen.

In sectie \ref{sec:opzet} staan we stil bij de opzet van het experiment en hoe de platformen geëvalueerd zijn.

In sectie \ref{sec:dataset} voorzien we meer uitleg rond het testscenario en de opgestelde dataset.

In sectie \ref{sec:validatie} wordt er toegelicht hoe de platformen op een objectieve manier geëvalueerd en vergeleken worden.

In sectie \ref{sec:werking-platformen} illustreren we de werking en functionaliteiten van de verschillende platformen. Daarbij wordt stilgestaan bij het creëren van een chatbot, het toevoegen van verschillende intents, het trainen met voorbeeldzinnen en hoe de gebouwde chatbots getest kunnen worden. 

In sectie \ref{sec:automatisatie} zal ten slotte meer informatie worden gegeven rond de praktische implementatie van het experiment en hoe het trainen en testen van de platformen geautomatiseerd wordt.


\section{Opzet}
\label{sec:opzet}

Om een vergelijking te kunnen maken van het begrijpend vermogen van de platformen, moet er een experiment plaatsvinden waarbij er op een objectieve manier beoordeeld wordt. Daarom werd er een dataset opgesteld waarmee alle platformen zullen getraind en geëvalueerd worden. Op deze manier krijgen alle platformen exact dezelfde informatie en kan er objectief beoordeeld worden. Een deel van de dataset zal gebruikt worden voor het trainen van de chatbots en het andere deel zal dienen voor het testen. Deze dataset zal bestaan uit een aantal intents met bijbehorende voorbeeldzinnen die bij dat bepaalde intent horen. Op deze manier kunnen de machine learning algoritmes modellen bouwen, die de juiste intent herkennen als een gebruiker een bericht naar de chatbot stuurt. Indien intents geen voorbeeldzinnen krijgen, dan zal het trainen onmogelijk zijn, wat een sterke invloed zal hebben op de accuraatheid. De meeste platformen vereisen een minimum van vijf voorbeeldzinnen om het trainen te kunnen starten, maar het is sterk aangewezen om minimum 10-15 voorbeeldzinnen per intent te voorzien \autocite{Greyling2019}. Eens het trainen gedaan is, kan het valideren beginnen. Het is de bedoeling om uiteindelijk een platform aan te duiden die het beste begrijpend vermogen heeft en dus het beste presteert op het herkennen van de juiste intent. Er zal op drie verschillende manieren geëvalueerd worden. Het hoofddoel van dit onderzoek is om te bepalen welk platform het beste presteert op intentherkenning. Daarbij wordt er beoordeeld op de prestaties bij zowel het gebruik met, als het gebruik zonder entities. Het is algemeen aangeraden om entities te gebruiken, maar in dit onderzoek wordt er ook gekeken naar de invloed op de resultaten als er entities worden gebruikt in tegenstelling tot de resultaten waar de entities zijn weggelaten. Daarnaast wordt er ook beoordeeld hoe goed de getrainde applicaties om kunnen gaan met taalvariaties. Gebruikers schrijven regelmatig geen standaard Nederlands als ze communiceren via het internet, daarom wordt er verwacht dat ze dit ook niet zullen doen als ze praten met een chatbot. Daardoor is het belangrijk dat een chatbot ook de intentie van berichten kan verstaan als gebruikers afkortingen, dialecten en slecht gevormde woorden en zinnen gebruiken.

\section{Dataset}
\label{sec:dataset}

De dataset is opgesteld op basis van een fictieve use case die werd bepaald in samenwerking met de co-promotor. Het is de bedoeling om een virtuele assistent te bouwen voor een busreisorganisatie. Het bedrijf wil mee met de digitale evolutie en wil gebruikers de mogelijkheid geven om interactie aan te gaan met een geautomatiseerde gesprekspartner om informatie te krijgen, eventuele klachten af te handelen en busreizen te boeken en te beheren. Daarbij zijn er een aantal intents gedefinieerd.

Er werd gekozen voor de volgende intents:
\begin{itemize}
    \item begroetingen
    \item geefBestemmingen
    \item geefReisTijden
    \item boekBusreis
    \item geefActueleInfo
    \item wijzigBusreis
    \item annuleerBusreis
    \item geefOnboardServices
    \item meldKlachten
    \item huurBusMetChauffeur
\end{itemize}

Voor het valideren van entityherkenning werd gekozen voor de volgende entities:
\begin{itemize}
    \item locatie
    \item datum
    \item aantal\_tickets
    \item tijdstip
    \item onboardService\_type
\end{itemize}

De entity onboardService\_type is een zelfgemaakte entity. Voor de andere entities werd gebruik gemaakt van systeementities die ingebouwd zitten in het platform. Op deze manier kunnen we de prestaties van zowel systeementities als zelfgemaakte entities beoordelen.


Elk van de intents werd voorzien van vijftien voorbeeldzinnen. Bij het opstellen van de voorbeeldzinnen was het belangrijk dat er rekening werd gehouden met een aantal zaken \autocite{Greyling2019}:
\begin{itemize}
    \item Gebruik korte en lange zinnen
    \item Verschillende synoniemen gebruiken
    \item Varieer de positie van entities
    \item Wissel grammatica af
    \item Gebruik woorden zowel in enkelvoud als in meervoud
    \item Gebruik niet altijd hoofdletters en leestekens
\end{itemize}

\section{Validatie}
\label{sec:validatie}

Chatbots zijn voorbeelden van gesuperviseerd leren, daarbij is het de bedoeling dat er op basis van trainingsdata modellen worden opgesteld die voor ongekende input de correcte output kunnen voorspellen. Dit zal ook binnen dit experiment worden toegepast. Er zijn vijftien voorbeeldzinnen voorzien per intent en het is de bedoeling dat er een deel van deze zinnen worden gebruikt om de chatbots te trainen. Het resterende deel wordt gebruikt om te valideren dat het model de juiste intent kan herkennen bij een gegeven input.

De meest gebruikte methode is om 80\% van de data te gebruiken om te trainen en dat de resterende 20\% wordt gebruikt om te testen \autocite{Desmarais2018}. Deze methode is vrij eenvoudig te implementeren, maar het probleem hierbij is dat niet alle data voor zowel trainen als testen gebruikt wordt. Dat kan resulteren in minder accurate resultaten.

De oplossing voor dit probleem is K-Fold Cross Validation \autocite{Desmarais2018}. Hierbij wordt de dataset in een aantal gelijke delen verdeeld en wordt er één deel gebruikt voor het testen, waarbij de resterende delen worden gebruikt om te trainen. Dit wordt een aantal keer herhaald, afhankelijk van het aantal delen dat je hebt gekozen, dat zijn het aantal cycli die doorlopen worden. Het meest gebruikte aantal delen is vijf, omdat er op deze manier aan het 80/20 principe kan voldaan worden. Vier delen worden dan gebruikt om de chatbot te trainen (80\%) en het andere deel om te valideren (20\%). Bij een volgende cyclus wordt er dan doorgeschoven. Het grote voordeel van deze methode is dat het veel betrouwbaarder en robuuster is, omdat er vijf keer zoveel testen zijn in vergelijking met de andere methode. Hierbij wordt ook alle data gebruikt voor zowel het trainen als het testen, wat het probleem van de bovenstaande methode oplost.

\begin{figure}[H]
    \label{fig:cross-validation-schema}
    \centering
    \includegraphics[width=0.85\textwidth]{schema-cross-validation}
    \caption{Grafische voorstelling van de werking van cross validation}
\end{figure}

\subsection{Confusion matrix}
\label{subsec:validatie-confusion-matrix}

Een confusion matrix is een duidelijke representatie van de resultaten van een classificatieprobleem. Het is een overzicht van hoeveel keer een categorie voorspeld werd en hoeveel keer dit juist of fout was. Het is ook duidelijk zichtbaar welke categorie werd gekozen indien het niet correct is. Vanuit een confusion matrix kunnen  interessante metrieken berekend worden. Berekeningen kunnen worden gedaan per categorie of in het geheel. Een voorbeeld van een confusion matrix voor een classificatieprobleem wordt geïllustreerd in onderstaande afbeelding. In dit onderzoek wordt vaak gebruik gemaakt van confusion matrices om de resultaten per platform te berekenen.

\begin{figure}[H]
    \label{fig:confusion-matrix-voorbeeld}
    \centering
    \includegraphics[width=0.85\textwidth]{confusion-matrix-voorbeeld}
    \caption{Voorbeeld van een confusion matrix}
\end{figure}

De linkerkant (de rijen) staan voor het dier die verwacht wordt en de kolommen staan voor het dier die voorspeld is. Hieruit kunnen er een aantal conclusies genomen worden:
\begin{itemize}
    \item Er zijn 53 (52+1) gevallen waarbij een hond verwacht werd. In 52 gevallen werd dit ook effectief voorspeld door het model. Eén keer werd een fout dier voorspeld, namelijk een kat.
    \item De katten en de koeien werden altijd voorspeld als ze verwacht werden.
    \item De dieren hond, dolfijn en koe werden nooit voorspeld als ze niet verwacht werden.
\end{itemize}

\subsection{Precision, Recall \& F-score}
\label{subsec:validatie-precision-recall-f-score}

Er zijn een aantal interessante metrieken die berekend kunnen worden uit een confusion matrix. Deze metrieken worden gebruikt om platformen met elkaar te vergelijken. Deze metrieken kunnen zowel berekend worden per intent/categorie, als in het geheel.

\subsubsection{Precision}

Precision is een metriek die aangeeft in hoeveel procent van de gevallen de voorspelde waarde ook effectief de juiste blijkt te zijn.
In bovenstaand voorbeeld kan er worden afgeleid dat een paard 21 (18+3) keer werd voorspeld. In 18 gevallen blijkt dit ook correct te zijn. Dat betekend dat de precision van deze categorie ongeveer 86\% (18/21) is. 

\subsubsection{Recall}

Recall is een andere metriek die aangeeft hoeveel procent van de categorieën correct voorspeld zijn. In bovenstaand voorbeeld zijn er 19 (18+1) voorbeelden waarbij een paard verwacht werd. In 18 gevallen werd het juiste dier herkend. Dat betekent dat de recall voor deze categorie ongeveer 95\% (18/19) is.

Initieel lijken de metrieken precision en recall sterk op elkaar, maar toch zijn ze volledig verschillend van elkaar, dat bewijst het voorbeeld.

\subsubsection{F-score}

Precision en recall vertellen weinig over de kwaliteit van het model \autocite{Treml2019}. Ze zijn enkel nuttig indien je zowel de precision als de recall kent. Om dit samen te voegen in één duidelijke metriek, bestaat er de F-score. Dat is het harmonisch gemiddelde van de recall en de precision. De F-score vertelt hoe kwalitatief een classificatiemodel is. Hoe hoger de F-score, hoe beter. Binnen dit onderzoek wordt de F-score gebruikt om de resultaten van de verschillende platformen met elkaar te vergelijken.

De F-score (harmonisch gemiddelde) bereken je als volgt:
\begin{itemize}
    \item F-score $= 2 * \frac{precision*recall}{precision+recall}\\$
\end{itemize}

In het voorbeeld van het paard is de F-score ongeveer gelijk aan 90\%.


\section{Werking van de platformen}
\label{sec:werking-platformen}


In deze sectie zal worden toegelicht hoe de verschillende platformen functioneren, dit is een belangrijk onderdeel binnen dit onderzoek. Er zal stilgestaan worden bij het creëren van een chatbot, het toevoegen van intents, het trainen met voorbeeldzinnen en hoe de gebouwde chatbots getest kunnen worden. Binnen deze sectie zullen ook de verschillende functionaliteiten van platformen worden toegelicht die niet gebruikt zijn voor het experiment. Dit experiment focust zich op het classificeren van intents en niet op een volledige conversatie met de chatbot. Toch is het belangrijk om stil te staan bij de mogelijkheden van elk platform om een volledig beeld te krijgen.

\subsection{Dialogflow}
\label{subsec:werking-platformen-dialogflow}

Dialogflow is een gebruiksvriendelijk platform dat zowel voor technische als geen technische mensen bruikbaar is, het helpt wel als je enige technische kennis hebt om alles beter te verstaan. Het enige dat nodig is om aan de slag te gaan met Dialogflow is een Google account. Iedereen kan ermee aan de slag, omdat het grotendeels gratis is. De betaalde versie is eerder voor bedrijven die complexe chatbots willen creëren die gebruik maken van functies die niet in de gratis versie zitten zoals de sentimentanalyses. De betalende versie is ook handig voor bedrijven die chatbots willen opzetten die meer verzoeken per minuut kunnen behandelen dan de limiet voor de gratis versie (zie sectie \ref{subsec:nlp-platformen-vegelijking-platformen}). Doordat Dialogflow onderdeel is van het Google Cloud Platform, kan er ook eenvoudig gebruik worden gemaakt van de diverse services van Google. Er zijn vele analysemogelijkheden aanwezig die gebruikt kunnen worden om de prestaties te monitoren. Dialogflow gebruikt de term agenten (agents) voor hun chatbots, ze doen dit, omdat ze de vergelijking willen maken met menselijke callcenter agenten \autocite{GoogleCloud2020}. Agenten verwerken conversaties met eindgebruikers, er zijn heel wat voorgebouwde agenten beschikbaar die gratis gebruikt kunnen worden. Bij het maken van een agent moet een naam opgegeven worden en moet er een standaardtaal gekozen worden. Het is mogelijk om extra talen toe te voegen indien er een meertalige agent gebouwd moet worden. Het is ook mogelijk om de agent te linken aan een Google Cloud project, op die manier is de samenwerking met andere diensten eenvoudiger. 

\begin{figure}[H]
    \label{fig:dialogflow-create}
    \centering
    \includegraphics[width=\textwidth]{dialogflow-create}
    \caption{Het creëren van een agent in Dialogflow}
\end{figure}

Agenten gebruiken intents om de intentie van berichten die gebruikers sturen te achterhalen. Bij het toevoegen en configureren van de intents, moet er een naam opgegeven worden en kunnen er diverse trainingszinnen toegevoegd worden. Dialogflow vereist een minimum van vijf voorbeeldzinnen per intent. Het is ook mogelijk om in de voorbeeldzinnen entities/parameters toe te voegen, er zijn heel wat entities ingebouwd in het systeem die gratis gebruikt kunnen worden. Per intent kunnen er ook antwoorden voorzien worden die de agent stuurt als die intent geclassificeerd wordt.

\begin{figure}[H]
    \label{fig:dialogflow-intent}
    \centering
    \includegraphics[width=\textwidth]{dialogflow-intent}
    \caption{Het aanmaken van een intent met voorbeeldzinnen in Dialogflow waarbij er ook entities worden aangeduid}
\end{figure}

In Dialogflow is het mogelijk om contexten te gebruiken, dit is gelijkaardig met de context in natuurlijke taal. Indien iemand zegt `Ik koop het`, dan moet de chatbot weten waar die 'het' naar verwijst. Dialogflow maakt gebruik van input en output contexten en kunnen toegevoegd worden aan intents. Input contexten zijn parameters die doorgegeven moeten worden aan een specifieke intent, voordat de die uitgevoerd kan worden. Output contexten zijn parameterwaarden die herkend worden in de intent en actief worden, zodat ze dan als input contexten in andere intents gebruikt kunnen worden. Bij elke intput context die er wordt toegevoegd, wordt er automatisch ook een output context toegevoegd. Het is wel mogelijk om extra output contexten toe te voegen indien dit nodig is. Onderstaande afbeelding bevat een voorbeeld van hoe contexten gebruikt kunnen worden in Dialogflow. Om de intent 'AnnuleerBusreis' uit te voeren, is het vereist dat de bestemming en datum gekend zijn, zonder die informatie is het niet mogelijk om te weten wat juist geannuleerd moet worden. Contexten en entities lijken erg op elkaar en dit kan voor verwarring zorgen. Een context is niets meer dan een entity die globaal gebruikt en doorgegeven kan worden doorheen verschillende intents. Contexten zullen in deze bachelorproef niet worden gebruikt, maar het is wel een interessante functie die Dialogflow heeft.

\begin{figure}[H]
    \label{fig:dialogflow-context}
    \centering
    \includegraphics[width=0.7\textwidth]{dialogflow-context}
    \caption{Het toevoegen van contexten in een intent in Dialogflow}
\end{figure}

Aangezien er heel wat systeementiteiten zijn voorzien in Dialogflow, kan het zijn dat het niet meteen nodig is om zelf entities aan te maken, maar het is wel mogelijk. Bij het aanmaken van een entiteit kunnen verschillende waarden toegevoegd worden om de agent deze entiteit te doen herkennen bij user input. Er kunnen synoniemen gegeven worden en er is een mogelijkheid om een specifiek patroon op te geven waarvoor een entiteit herkend wordt in zinnen. De gemaakte entiteiten kunnen dan net zoals systeementiteiten toegevoegd worden aan voorbeeldzinnen in de intents. In deze bachelorproef wordt indien mogelijk altijd 'fuzzy matching' gebruikt bij de entiteiten. Deze optie zorgt ervoor dat woorden die verkeerd geschreven zijn en spellingsfouten bevatten, toch herkend kunnen worden als entiteit zonder dat de woorden perfect juist geschreven hoeven te zijn.

\begin{figure}[H]
    \label{fig:dialogflow-entity}
    \centering
    \includegraphics[width=\textwidth]{dialogflow-entity}
    \caption{Het aanmaken en beheren van een entiteit in Dialogflow}
\end{figure}

Met Dialogflow is het mogelijk om als ontwikkelaar eerdere berichten die eindgebruikers hebben gestuurd naar de agent te valideren, zodat die zinnen gebruikt kunnen worden als extra voorbeeldzinnen bij de intents. Op deze manier wordt de agent steeds slimmer doorheen zijn levensloop, doordat hij meer data krijgt. In onderstaande afbeelding is weergegeven hoe je dit als ontwikkelaar kunt doen. Alle berichten die gebruikers naar de agent hebben gestuurd, staan hier chronologisch weergegeven. Daarbij staat ook vermeld welke intent herkend werd door de agent op dat moment. Door middel van de vinkjes, annuleer-tekens of vuilbakjes, kun je aangeven wat je hiermee precies wilt doen. Met een groen vinkje bevestig je dat de herkende intent ook de juiste was en met het vuilbakje geef je aan dat het fout was en dat je dit niet wil toevoegen als een extra voorbeeldzin. De annuleer-tekens worden gebruikt om aan te geven dat de intentherkenning fout was en dat je dit bericht wilt toevoegen aan de default fallback intent. Indien een intentherkenning fout was, kun je ook de herkende intent wijzigen en toch goedkeuren. Met de approve knop bovenaan, wordt alles definitief opgeslaan en verdwijnen deze berichten uit de lijst. De berichten waarbij er een groen vinkje stond, worden toegevoegd als nieuwe voorbeeldzinnen bij de respectievelijke intent. Op termijn kun je op deze manier een erg grote lijst van voorbeeldzinnen per intent bekomen, wat goed is voor de kwaliteit van de agent.

\begin{figure}[H]
    \label{fig:dialogflow-validate}
    \centering
    \includegraphics[width=\textwidth]{dialogflow-validate}
    \caption{Het valideren van user input om het model uit te breiden in Dialogflow}
\end{figure}

Dialogflow is eenvoudig te integreren met andere diensten. Het enige dat je hiervoor als ontwikkelaar moet doen, is de integratie aanzetten op een scherm in Dialogflow. Er komt daarna informatie beschikbaar op het scherm die uitlegt wat je precies moet doen om het werkende te krijgen. Het is ook mogelijk om zelf een applicatie te schrijven die gebruik maakt van de API van Dialogflow.

\begin{figure}[H]
    \label{fig:dialogflow-integrations}
    \centering
    \includegraphics[width=\textwidth]{dialogflow-integrations}
    \caption{Het integreren van een Dialogflow agent in andere diensten}
\end{figure}

De chatbot testen kan via de user interface (UI) gebeuren. Dit kan worden gedaan door een bericht te sturen naar de ingebouwde conversatiemodule. Bij het sturen van een bericht krijg je informatie over welke intent is herkend, wat het antwoord is en welke paramaters herkend werden. Het is ook mogelijk om meer gedetailleerde resultaten te zien. Opnieuw zal er in deze bachelorproef geen speciale aandacht besteed worden aan het antwoorden naar gebruikers.

\begin{figure}[H]
    \label{fig:dialogflow-test}
    \centering
    \includegraphics[width=0.5\textwidth]{dialogflow-test}
    \caption{Het testen van de agent met de conversatiemodule in Dialogflow}
\end{figure}

\subsection{IBM Watson}
\label{subsec:werking-platformen-ibm-watson}

IBM Watson is het chatbotplatform die ontwikkeld is door IBM. Het is een onderdeel van IBM Cloud, wat goed vergelijkbaar is met Google Cloud, want ze bieden ongeveer dezelfde functionaliteiten aan. Om een chatbot op te zetten heb je enkel een IBM Cloud account nodig. IBM Watson is gekend voor zijn zeer gebruiksvriendelijke grafische user interface (GUI) en voor de snelheid waarmee een chatbot ontwikkeld kan worden. IBM Watson biedt ook analysemogelijkheden aan op hun chatbotplatform en gebruikt de naam 'assistent' voor hun chatbots. Het aanmaken van een assistent is heel eenvoudig, want er wordt enkel een naam en een beschrijving gevraagd.

\begin{figure}[H]
    \label{fig:watson-create}
    \centering
    \includegraphics[width=0.75\textwidth]{watson-create}
    \caption{Het aanmaken van een assistent in IBM Watson}
\end{figure}

IBM werkt voor het trainen van zijn assistenten met zogenaamde skills, deze bevatten alles om vragen van klanten te kunnen beantwoorden. Bij IBM Watson wordt er niet per assistent getraind, maar er wordt een skill aangemaakt die kan worden toegevoegd aan de assistent naar keuze. Er kunnen dus meerdere skills aan één assistent toegevoegd worden. Bij het aanmaken van een skill is het noodzakelijk om een naam en een standaardtaal op te geven. Door verschillende skills met verschillende talen toe te voegen aan een assistent, kan er dus ook een meertalige chatbot gemaakt worden.

\begin{figure}[H]
    \label{fig:watson-skill}
    \centering
    \includegraphics[width=0.75\textwidth]{watson-skill}
    \caption{Het aanmaken van een skill in IBM Watson}
\end{figure}

Eens een skill is aangemaakt, kan het configureren van de skill beginnen. Het toevoegen van een intent is ook hier eenvoudig, want er is enkel een naam en een aantal voorbeeldzinnen nodig. IBM Watson legt geen restricties op het aantal voorbeeldzinnen, maar opnieuw is het aangeraden om er 10-15 te voorzien per intent. Het configureren van intents verschilt ook met de andere platformen, omdat er geen entities toegevoegd kunnen worden aan de intents en aan de voorbeeldzinnen. In de andere platformen moet je zelf aanduiden welke woorden in de zin behoren tot een entity. In onderstaand voorbeeld is het duidelijk dat je 9 augustus niet zelf moet toewijzen aan de entiteit 'datum'. Dat is een functionaliteit die IBM met hun chatbotplatform achter de schermen gaat doen voor de ontwikkelaar. Watson gaat zelf op zoek naar entiteiten in de voorbeeldzinnen zonder dat de ontwikkelaar daar enige tijd in hoeft te stoppen om ze zelf allemaal aan te duiden. Dat betekent dat het proces van het ontwikkelen van een chatbot efficiënter kan verlopen. Watson heeft net zoals bovenstaande platformen een aantal ingebouwde entities waarvoor je niets hoeft te doen. Hoe goed deze methode zal werken, zal blijken uit het experiment.

\begin{figure}[H]
    \label{fig:watson-intent}
    \centering
    \includegraphics[width=0.75\textwidth]{watson-intent}
    \caption{Het configureren van een intent in IBM Watson}
\end{figure}

In IBM Watson kunnen ook eigen entiteiten toegevoegd worden, dat komt vrijwel volledig overeen met hoe dat gedaan wordt in Dialogflow. Er kunnen waarden voor die entiteit toegevoegd worden alsook synoniemen. Het is ook mogelijk om op basis van patronen entiteiten uit berichten te halen. Het enige verschil met Dialogflow is de manier waarop entiteiten gebruikt worden, want zoals eerder vermeld moet de ontwikkelaar buiten het creëren van de entiteit niets doen om het te gebruiken, de entiteiten moeten niet aangeduid worden in de voorbeeldzinnen in de intents.

\begin{figure}[H]
    \label{fig:watson-entity}
    \centering
    \includegraphics[width=0.9\textwidth]{watson-entity}
    \caption{Het configureren van een entiteit in IBM Watson}
\end{figure}

Het is met IBM Watson ook mogelijk om een volledige conversatieflow van een skill vast te leggen. Als ontwikkelaar kan je verschillende nodes en subnodes toevoegen en die volledig configureren naar eigen wens. Deze nodes kunnen worden uitgevoerd als een intent, contextvariabele of entity herkent wordt door het model. In de nodes kunnen er ook antwoorden voorzien worden die de assistent zal geven, deze functionaliteit zal binnen deze bachelorproef niet beoordeeld worden, omdat dit geen invloed heeft op de prestaties van intent classificatie. Het is immers wel een interessante functionaliteit die een rol kan spelen in het kiezen naar een platform.

\begin{figure}[H]
    \label{fig:watson-dialogen}
    \centering
    \includegraphics[width=0.75\textwidth]{watson-dialogen}
    \caption{Conversatieflow die zelf samengesteld kan worden in IBM Watson}
\end{figure}

\begin{figure}[H]
    \label{fig:watson-node}
    \centering
    \includegraphics[width=0.75\textwidth]{watson-node}
    \caption{Het configureren van een node van in de conversatieflow in IBM Watson}
\end{figure}

Watson biedt een beperkt aantal ingebouwde integraties aan (Facebook \& Slack), maar het is wel mogelijk om zelf een applicatie te bouwen die gebruik maakt van de aangeboden API.

De gebouwde skills kunnen ook getest worden via een ingebouwde conversatiemodule. Bij het versturen van een bericht, wordt er een antwoord gegeven waarin duidelijk wordt aangegeven welke intent is herkend.

\begin{figure}[H]
    \label{fig:watson-test}
    \centering
    \includegraphics[width=0.65\textwidth]{watson-test}
    \caption{Het testen van IBM Watson via de ingebouwde interface}
\end{figure}

\subsection{LUIS}
\label{subsec:werking-platformen-luis}

LUIS staat voor Language Understanding Intelligent Service en is de NLU-tool van Microsoft en is onderdeel van het Microsoft Azure cloud service platform. Dat is opnieuw goed vergelijkbaar met Google Cloud en met IBM Cloud. LUIS is een pure NLU-tool en kan dus niet worden gebruikt om dialooglogica uit te werken. Daarvoor kan het geïntegreerd worden met het Microsoft Bot Framework, dat ook onderdeel is van Azure en wel op berichten van eindgebruikers kan antwoorden en dialogen kan voeren. LUIS is ook onderdeel van dat framework, het wordt gewoon gezien als een individuele dienst. Het creëren van een applicatie met LUIS is ook eenvoudig, doordat er een gebruiksvriendelijke interface voorzien is, net zoals alle voorgaande platformen. Om een applicatie aan te maken heb je enkel een Microsoft account nodig en moet je een naam en taal selecteren.

\begin{figure}[H]
    \label{fig:luis-create}
    \centering
    \includegraphics[width=0.65\textwidth]{luis-create}
    \caption{Het aanmaken van een applicatie via LUIS}
\end{figure}

Het toevoegen en configureren van intents is vrij gelijkaardig aan de manier die Dialogflow toepast. Het is opnieuw belangrijk dat er genoeg voorbeeldzinnen per intent zijn om ervoor te zorgen dat de applicatie goed getraind kan worden. LUIS gebruikt de naam 'utterances' om voorbeeldzinnen te beschrijven. Bij LUIS is het opnieuw vereist om zelf aan te geven welke woorden entiteiten zijn, dit kunnen zowel systeementiteiten als zelfgemaakte entiteiten zijn.

\begin{figure}[H]
    \label{fig:luis-intent}
    \centering
    \includegraphics[width=0.85\textwidth]{luis-intent}
    \caption{Het configureren van een intent in LUIS}
\end{figure}

LUIS biedt een een grote hoeveelheid vooraf gebouwde intents, entities en zelfs domeinen aan. Domeinen zijn een verzameling van vooraf getrainde modellen van intents en entities die samenwerken. Dit wordt niet ondersteund in het Nederlands en zal daarom niet verder worden besproken. Verder is het mogelijk om zelf entities toe te voegen en te gebruiken. Indien je als ontwikkelaar systeementiteiten wil gebruiken, is het wel noodzakelijk om die eerst toe te voegen, want indien je dit niet doet, zal het niet mogelijk zijn om ze te gebruiken in de utterances. Er zijn verschillende soorten entiteittypes om uit te kiezen. Opvallend is wel dat er bij LUIS geen waarden voor de entiteit moeten meegegeven worden. Dat betekent dat het niet nodig is om bijvoorbeeld de waarden 'morgen' of 'vrijdag' toe te kennen aan de entiteit 'datum'.

\begin{figure}[H]
    \label{fig:luis-entity}
    \centering
    \includegraphics[width=0.65\textwidth]{luis-entity}
    \caption{Het aanmaken van een entiteit binnen LUIS}
\end{figure}

Met LUIS is het net zoals bij Dialogflow mogelijk om als ontwikkelaar eerdere berichten die eindgebruikers hebben gestuurd naar de applicatie te valideren. Het enige verschil bij LUIS is dat enkel utterances waarover hij onzeker is, nog moeten gevalideerd worden door de ontwikkelaar, de rest gebeurt automatisch.

\begin{figure}[H]
    \label{fig:luis-validate}
    \centering
    \includegraphics[width=\textwidth]{luis-validate}
    \caption{Het beoordelen van utterances waarover LUIS onzeker is}
\end{figure}

Voor LUIS getest kan worden, is het verplicht om het model te trainen, dit moet manueel gebeuren. Indien je dit niet doet, is het niet mogelijk om berichten te sturen naar de chatbot.

\begin{figure}[H]
    \label{fig:luis-train}
    \centering
    \includegraphics[width=0.65\textwidth]{luis-train}
    \caption{Het manueel trainen van de LUIS applicatie}
\end{figure}

Eens de applicatie getraind is, kan er getest worden, dit kan gebeuren via een ingebouwde module. Bij het versturen van een bericht naar de gebouwde LUIS app, krijgt de gebruiker informatie over welke intent herkend is.
Het is duidelijk zichtbaar welke entities herkend zijn. Ook zal LUIS automatisch een sentimentanalyse uitvoeren, daarbij wordt aangegeven hoe positief of negatief LUIS dit bericht interpreteert.

\begin{figure}[H]
    \label{fig:luis-test}
    \centering
    \includegraphics[width=0.75\textwidth]{luis-test}
    \caption{Het testen van een LUIS applicatie}
\end{figure}

\subsection{Wit.ai}
\label{subsec:werking-platformen-wit}

Wit.ai is de NLU-tool van Facebook en is volledig gratis te gebruiken. Het heeft net zoals de vorige platformen een eenvoudige grafische user interface die gebruikt kan worden. Het enige dat je nodig hebt om aan de slag te gaan met Wit.ai is een Github account of een Facebook account. Het staat volledig gratis gehost op het internet en kan via de API bereikt worden. Het bevat geen mogelijkheid om dialogen te configureren en antwoorden in te stellen. Indien je dit wenst, moet er zelf een applicatie worden ontwikkeld die gebruik maakt van de aangeboden API.

Het aanmaken van een applicatie binnen Wit.ai is heel erg eenvoudig, een naam en een standaardtaal zijn de enige vereisten. Het is ook mogelijk om een applicatie te importeren van een backup en er is de keuze om de data die verwerkt wordt in de applicatie te delen met de volledige community of niet.

\begin{figure}[H]
    \label{fig:wit-create}
    \centering
    \includegraphics[width=0.75\textwidth]{wit-create}
    \caption{Het aanmaken van een applicatie in Wit.ai}
\end{figure}

Eenmaal de applicatie aangemaakt is, kan het trainen beginnen. De werking van intents en entities binnen Wit.ai wijkt af van hoe de andere platformen hiermee omgaan. Binnen Wit.ai bestaan er enkel entities, geen intents, intents worden gezien als een instantie van een entity. Parameterwaarden worden dus ook als entities gezien, net zoals intents. Bij het toevoegen van nieuwe trainingsdata, moet dus altijd minstens één entity toegevoegd worden, namelijk de entity ‘intent’. Net zoals bij andere entities kunnen dan verschillende waarden toegevoegd worden, deze waarden komen dan overeen met de namen van de mogelijke intents. Dit klinkt erg verwarrend, maar onderstaande voorbeelden verduidelijken deze werking.

\begin{figure}[H]
    \label{fig:wit-train}
    \centering
    \includegraphics[width=0.65\textwidth]{wit-train}
    \caption{Het trainen van een Wit.ai applicatie}
\end{figure}

\begin{figure}[H]
    \label{fig:wit-intent}
    \centering
    \includegraphics[width=0.65\textwidth]{wit-intent}
    \caption{Het kiezen van een intent bij het trainen in Wit.ai}
\end{figure}

Net zoals bij de andere platformen is het mogelijk om extra entities toe te wijzen aan woorden in de voorbeeldzinnen. Er is keuze uit een aantal voorgedefinieerde entities, maar het is ook mogelijk om zelf entities aan te maken en te gebruiken.

\begin{figure}[H]
    \label{fig:wit-entity}
    \centering
    \includegraphics[width=0.65\textwidth]{wit-entity}
    \caption{Het aanduiden van entities in een voorbeeldzin in Wit.ai}
\end{figure}

Het is opnieuw mogelijk om extra waarden en synoniemen toe te voegen aan de entities, net zoals in de andere platformen.

\begin{figure}[H]
    \label{fig:wit-intent-manage}
    \centering
    \includegraphics[width=0.85\textwidth]{wit-entity-manage}
    \caption{Het configureren van entities in Wit.ai}
\end{figure}

Wit.ai bevat geen module om de gebouwde applicatie te valideren, het biedt wel een API aan om dat te doen. Deze API zal later ook gebruikt worden om training te automatiseren, maar meer hierover in een latere sectie. Om gebruik te maken van deze API, werd een tool, genaamd Postman, gebruikt. Daarmee kan eenvoudig een verzoek naar de server van Wit.ai verstuurd worden om de chatbot te testen.

\begin{figure}[H]
    \label{fig:wit-test}
    \centering
    \includegraphics[width=0.75\textwidth]{wit-test}
    \caption{Voorbeeld van een request met Postman naar de server van Wit.ai om de applicatie te testen}
\end{figure}

\subsection{Rasa}
\label{subsec:werking-platformen-rasa}

Zoals eerder vermeld is Rasa een tool die qua gebruik sterk afwijkt van de eerder besproken platformen, omdat het meer technische kennis vereist in vergelijking met de andere. Om gebruik te maken van Rasa moet het platform eerst lokaal gedownload worden. De makkelijkste manier om dit te doen is door gebruik te maken van Pip. Pip is een tool die gebruikt wordt om softwarepakketten die geschreven zijn in de programmeertaal Python te installeren. Rasa biedt in tegenstelling tot de eerder besproken platformen ook geen grafische user interface (GUI) aan. Dit betekent dat alles in de command line interface (CLI) moet gebeuren. De CLI is de grote tegenhanger van de GUI en is een andere manier om met software te communiceren, want de CLI wordt enkel gebruikt op basis van tekstcommando's.

\begin{figure}[H]
    \label{fig:rasa-install}
    \centering
    \includegraphics[width=0.35\textwidth]{rasa-install}
    \caption{Voorbeeld van een commando binnen de CLI waarbij Rasa geïnstalleerd wordt door middel van Pip}
\end{figure}

Eens Rasa succesvol geïnstalleerd is, kan er een project opgestart worden, dat kan met het commando ‘rasa init’. Daarbij zal er de vraag komen in welke map het project geïnstalleerd moet worden en of dat er een voorbeeldmodel getraind moet worden. Eens dat gelukt is, kan de configuratie van de chatbot beginnen.

\begin{figure}[H]
    \label{fig:rasa-create}
    \centering
    \includegraphics[width=\textwidth]{rasa-create}
    \caption{Het creëren van een project met Rasa in de CLI}
\end{figure}

Rasa bestaat uit twee hoofdmodules, Rasa NLU en Rasa Core. De focus binnen dit onderzoek zal liggen op Rasa NLU. Dit is de intentclassificatiemodule van Rasa die nodig is om het begrijpend vermogen van een chatbot te evalueren. Rasa Core is essentieel voor het vastleggen van dialogen en antwoorden richting de eindgebruiker. Rasa werkt zoals de andere platformen ook met intents en entities. Het configureren ervan gebeurt in een bestand genaamd ‘nlu.md’ dat aangemaakt wordt bij het creëren van een project. Daarin kunnen heel eenvoudig intents met bijhorende voorbeeldzinnen toegevoegd worden. Entities moeten binnen Rasa ook niet vooraf gedefinieerd worden, ze kunnen direct aangeduid worden in de voorbeeldzinnen en Rasa doet de rest. Het is ook mogelijk om synoniemen te voorzien voor entities en om entities te herkennen op basis van patronen.

\begin{figure}[H]
    \label{fig:rasa-intent}
    \centering
    \includegraphics[width=0.85\textwidth]{rasa-intent}
    \caption{Het configureren van de intents en voorbeeldzinnen met entities in Rasa}
\end{figure}

Het moeilijkste deel bij het gebruik van Rasa is het vastleggen van de configuratie van Rasa NLU en Rasa Core. Rasa kan door de ontwikkelaar volledig op maat van een project afgesteld worden. Berichten die via Rasa binnenkomen, worden verwerkt door softwarepakketten die je als ontwikkelaar zelf kunt kiezen. Dit wordt in de andere platformen achter de schermen voor ons gedaan, waardoor er hier niet altijd controle over is. Binnen deze bachelorproef wordt er beperkt tot de Nederlandse taal, dus moeten er componenten worden gebruikt die Nederlands ondersteunen. De configuratie vastleggen kan opnieuw via een bestand (config.yml) die bij het creëren aangemaakt werd. Bij het vastleggen van de configuratie werden de aanbevelingen vanuit de officiële documentatie gebruikt. Het voornaamste is dat er componenten worden gebruikt die overweg kunnen met de Nederlandse taal. Voor entityherkenning werd eveneens een specifieke component gebruikt, dat is nodig om entiteiten zoals locaties, datums, tijdstippen, etc. te kunnen extraheren. Deze component werd enkel gebruikt voor experimenten waarbij entities nodig zijn. De configuratie van Rasa Core heeft eveneens tal van mogelijkheden, maar dit behoort niet tot de scope van deze bachelorproef. Over alle opties en mogelijkheden van Rasa, kan een volledige bachelorproef geschreven worden. 

\begin{figure}[H]
    \label{fig:rasa-config}
    \centering
    \includegraphics[width=0.80\textwidth]{rasa-config}
    \caption{Configuratie van Rasa NLU}
\end{figure}

Met Rasa Core is het zoals eerder vermeld mogelijk om dialogen en antwoorden naar eindgebruikers te configureren. Rasa Core wordt standaard mee geïnstalleerd, maar zal binnen deze bachelorproef niet verder gebruikt en besproken worden.

Eens de configuratie van Rasa is gebeurd en er een aantal intents toegevoegd zijn, kan het trainen en testen van de chatbot gebeuren. Het is mogelijk om afzonderlijke modules te trainen. Om enkel de NLU-module te trainen, moet er in de CLI het commando ‘rasa train nlu’ uitgevoerd worden.

\begin{figure}[H]
    \label{fig:rasa-train}
    \centering
    \includegraphics[width=0.5\textwidth]{rasa-train}
    \caption{Het trainen van de NLU module van Rasa}
\end{figure}

Als de training succesvol afgerond is, dan is het mogelijk om de NLU-module te testen. Dit kan gedaan worden door het commando ‘rasa shell nlu’ uit te voeren. Daarbij wordt een lokale server opgestart waarnaar berichten kunnen worden gestuurd en intents en entities herkend kunnen worden. Indien deze server publiek toegangelijk moet zijn, kan het eventueel op Google Cloud, AWS of Microsoft Azure gezet worden. Bij antwoord van de server is de herkende intent zichtbaar, alsook de herkende entities. Bij de intent staat er aangegeven hoe zeker de applicatie is van de intent die hij heeft gekozen, in onderstaand voorbeeld is dit 99.985\%, wat goed is, want meestal ligt dit percentage lager.

\begin{figure}[H]
    \label{fig:rasa-test}
    \centering
    \includegraphics[width=0.5\textwidth]{rasa-test}
    \caption{Voorbeeld van een response bij het sturen van een bericht naar de NLU-module}
\end{figure}

\section{Automatisatie}
\label{sec:automatisatie}

Tot nu toe werd er telkens via een user interface rechtstreeks gewerkt op de verschillende platformen om bijvoorbeeld een model te trainen of te testen. Deze manier van werken is goed, maar zal bij grote hoeveelheden data heel veel tijd in beslag nemen. Stel je maar voor dat er 10 000 voorbeeldzinnen  en 100 intents zijn en dat dit via de user interface moet ingevoerd worden. Volgens 5-fold cross validation moeten er dan een aantal keer 8000 zinnen getraind worden en 2000 zinnen getest. Dit zou volgens de werking in de sectie hierboven beschreven enorm veel tijd in beslag nemen en onbeheersbaar worden. Om dit op te lossen bieden de platformen een oplossing aan genaamd een API. Dit is een andere manier om te communiceren met de platformen. Het is mogelijk om vanuit een eigen geprogrammeerde applicatie te communiceren met deze API’s en eigenlijk van volledig dezelfde functionaliteiten gebruik te maken als hierboven beschreven, zonder dat er rechtstreeks op de platformen moet gewerkt worden. Dit betekent dat we zelf de code kunnen schrijven die het volledige proces van het trainen en het valideren van de platformen kan automatiseren door gebruik te maken van die API’s. De platformen bieden ook een andere oplossing voor dit probleem aan, genaamd SDK's. Dat staat voor Software Development Kit en dat is een tool die de werking met de platformen vanuit eigen geschreven code eenvoudiger maakt. Achterliggend zullen SDK's ook gebruik maken van de API's, maar de ontwikkelaar moet daar zelf minder voor instaan. Binnen deze bachelorproef werd verder enkel nog gebruik gemaakt van de verschillende API’s en SDK's. Dit met het resultaat dat het experiment veel sneller uitgevoerd en herhaald kan worden zonder dat dit manueel via de user interface van de platformen moet gebeuren.

Alle automatisatiescrips zijn geschreven in de programmeertaal Python en maken gebruik van de API’s en SDK's aangeboden door de verschillende platformen. Er zijn scripts geschreven voor zowel het trainen, als het testen van de verschillende platformen voor alle experimenten die uitgevoerd zijn. Voor het toepassen van cross validation werd eveneens een script geschreven die de initiële dataset willekeurig verdeeld in vijf verschillende delen en daarmee dan de juiste train-en-test datasets mee zal vormen zoals beschreven in sectie 3.3. Daarvoor werd gebruik gemaakt van Scikit-learn, een softwarepakket dat verschillende functionaliteiten voor machine learning aanbiedt voor de programmeertaal Python. Scikit-learn bevat een module die cross validation zal uitvoeren \autocite{sklearn2020}. De gevormde datasets worden weggeschreven in bestanden die door de andere scripts gebruikt worden voor het trainen en het valideren.

\begin{figure}[H]
    \label{fig:code-kfold}
    \centering
    \includegraphics[width=\textwidth]{code-kfold}
    \caption{Script voor het uitvoeren van cross validation op een initiële dataset en de gevormde datasets weg te schrijven naar nieuwe bestanden om gebruikt te kunnen worden door andere train-en-validatie scripts}
\end{figure}

\begin{figure}[H]
    \label{fig:code-validatie}
    \centering
    \includegraphics[width=\textwidth]{code-test}
    \caption{Voorbeeld van een Python script waarbij intentherkenning zonder entities van Wit.ai wordt gevalideerd door middel van een dataset van testzinnen en waarbij de resultaten worden weggeschreven naar een nieuw bestand}
\end{figure}

























